<!DOCTYPE html>
<html lang="en">

<head>
	<title></title>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<!-- Styling -->
	<link href="css/reset.css" rel="stylesheet">
	<link href="css/main.css" rel="stylesheet">

	<link href="css/bounce.css" rel="stylesheet">


	<!-- Fonts -->
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Gamja+Flower&family=Hanken+Grotesk:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Space+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet"> 

	<!-- highlight.js -->
	<link rel="stylesheet" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/grayscale.css">
	<link rel="stylesheet" media="(prefers-color-scheme: dark)" href="css/grayscale-dark.css">
	<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/glsl.min.js"></script>
	<script>hljs.highlightAll();</script>

	<!-- MathJax -->
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
	<div class="main-container">
		<h1>
			How to bounce a ball
		</h1>

		<p>
			My intention with this blog is to demonstarte and explain some of the core concepts behind 5 native features the browser provides.
			With this said, I will skip some of the boilerplate that comes with using these features directly.
		</p>
		<p>
			Although there are libraries that can facilitate the use of these features,
			I believe that understanding the core concepts behind them allow one to make a better use of these libraries.
		</p>

		<h2>
			CSS
			<br/>
			-
			<br/>
			Transformation
		</h2>

		<p>
			CSS animations allow you to define a transition between two states of CSS properties like color, position, size, and others.
			You define the animation transitions with keyframes, specifying a stage by percentage representing the point in time of the transition.
		</p>

		<pre>
			<code class="language-css hljs-grayscale">
.bounce {
	animation-duration: 0.36106s;
	animation-name: bounce-animation;
	animation-iteration-count: infinite;
}

@keyframes bounce-animation {
	from {
		transform:
			translateY(0px)
			rotateZ(0deg);
		animation-timing-function:
			cubic-bezier(0.33, 0, 0.66, 0.33);
	}
	45% {
		transform:
			translateY(250px)
			rotateZ(360deg);
	}
	50% {
		transform:
			scale(1.25, 0.75);
			translateY(257px)
			rotateZ(360deg)
		animation-timing-function:
			cubic-bezier(0.33, 0.66, 0.66, 1);
	}
	55% {
		transform:
			translatee(250px)
			rotateZ(360deg)
			scale(1, 1);
	}
	to {
		transform:
			translateY(0px)
			rotateZ(720deg);
	}
}
			</code>
		</pre>

		<p>
			Here we define a class <code>bounce</code> for our <code>&ltdiv&gt</code> element.
			This bounce class contains the name, duration and repetition that represents our animation.
			We have specified that our animation <code>bounce-animation</code> should last <code>0.36106s</code> and should repeat an <code>infinite</code> amount of times.
		</p>

		<p>
			Our <code>bounce-animation</code> is represented by the <code>@keyframes</code> object.
			To simulate a fall we will <code>transform</code> our position in the y-axis using the <code>translateY</code> function.
			We go <code>from</code> an offset of <code>0px</code>, all the way <code>to</code> an offset of <code>0px</code>.
		</p>

		<p>
			The reason for this is that we want our animation to finish at the same place where it started so that we can loop it infinitely.
			Knowing this, we can expect the ball to bounce half way through the animation.
			So we specify that at <code>50%</code> our animation should translate <code>250px</code>.
		</p>

		<p>
			Besides this, you may have noticed the <code>rotateZ</code> and <code>scale</code> functions.
			The rotation will be more obvious on the next example and the scaling is to add a squishing effect.
			But what is the <code>animation-timing-function</code>?
			This is used to determine the intermediate values between keyframes.
		</p>

		<p>
			The function and values <code>cubic-bezier(0.33, 0, 0.66, 0.33)</code> are an approximation of a parabola which fits our use for a free falling ball.
			We then switch it half way through the animation because we need the inverse behavior.
			With an <code>animation-duration</code> of <code>0.36106s</code>, this gives a pretty good simulation of a bouncing ball.
		</p>

		<!-- CSS/HTML -->
		<div class="container border">
			<div class="ball top bounce real-duration">
			</div>
		</div>

		<h2>
			SMIL
			<br/>
			-
			<br/>
			Morphing
		</h2>

		<p>
			SMIL (Synchronized Multimedia Integration Language) is a markup language that can be used in conjunction with SVG.
			It allows you to create animations in a declarative way similarly to CSS.
			There are some things that CSS can't animate and so SMIL has some advantage over this.
		</p>

		<p>
			For this animation we will take advantage of our previous example and we'll use our already existing CSS <code>bounce</code> class.
			We will use SMIL to morph the ball between a circle and a square, and the rotating animation that I mentioned earlier will help us visualize the rotating square a little bit better.
		</p>

		<pre>
			<code class="language-html hljs-grayscale">
&lt;path&gt;
	&lt;animate
		attributeName="d"
		dur="0.36106s"
		repeatCount="indefinite"
		values="
			M 70.114583,19.84375 C 67.909722,22.048611 65.704861,24.253472 63.5,26.458333 61.295139,24.253472 59.090278,22.048611 56.885417,19.84375 59.090278,17.638889 61.295139,15.434028 63.5,13.229167 c 2.204861,2.204861 4.409722,4.409722 6.614583,6.614583 z;
			m 70.114583,19.84375 c 0,3.649245 -2.96546,6.614583 -6.614583,6.614583 -3.649243,0 -6.614583,-2.965459 -6.614583,-6.614583 0,-3.649243 2.96546,-6.614583 6.614583,-6.614583 3.649243,0 6.614583,2.965459 6.614583,6.614583 z;
			M 70.114583,19.84375 C 67.909722,22.048611 65.704861,24.253472 63.5,26.458333 61.295139,24.253472 59.090278,22.048611 56.885417,19.84375 59.090278,17.638889 61.295139,15.434028 63.5,13.229167 c 2.204861,2.204861 4.409722,4.409722 6.614583,6.614583 z;
		" /&gt;
&lt;/path&gt;
			</code>
		</pre>

		<p>
			Here I am just showing the <code>&lt;path/&gt;</code> element of the <code>svg</code> that we will render.
			The <code>d</code> attribute defines the path to be drawn.
			We won't specify it directly on the <code>path</code> element, but we will add an <code>animate</code> child element that we will use to morph this attribute and we'll initialize it there.
		</p>

		<p>
			So in the <code>animate</code> element we add an attribute <code>attributeName</code> that specifies that we will modify the <code>d</code> attribute of the <code>path</code> element.
			The <code>dur</code> attribute specifies the duration of a single cycle of the animation.
			The <code>repeatCount</code> attribute specifies how many times the animation will be repeated.
			And lastly, the <code>values</code> attribute defines a list of values that we'll interpolate in between as we move through the animation.
		</p>

		<!-- SVG -->
		<div class="container border">
			<svg width="13.229167mm" height="13.229167mm" viewBox="0 0 13.229167 13.229167" class="bounce fake-duration">
				<g transform="translate(-56.885417,-13.229167)">
					<path>
						<animate
							attributeName="d"
							dur="1s"
							repeatCount="indefinite"
							values="
								M 70.114583,19.84375 C 67.909722,22.048611 65.704861,24.253472 63.5,26.458333 61.295139,24.253472 59.090278,22.048611 56.885417,19.84375 59.090278,17.638889 61.295139,15.434028 63.5,13.229167 c 2.204861,2.204861 4.409722,4.409722 6.614583,6.614583 z;
								m 70.114583,19.84375 c 0,3.649245 -2.96546,6.614583 -6.614583,6.614583 -3.649243,0 -6.614583,-2.965459 -6.614583,-6.614583 0,-3.649243 2.96546,-6.614583 6.614583,-6.614583 3.649243,0 6.614583,2.965459 6.614583,6.614583 z;
								M 70.114583,19.84375 C 67.909722,22.048611 65.704861,24.253472 63.5,26.458333 61.295139,24.253472 59.090278,22.048611 56.885417,19.84375 59.090278,17.638889 61.295139,15.434028 63.5,13.229167 c 2.204861,2.204861 4.409722,4.409722 6.614583,6.614583 z;
							" />
					</path>
				</g>
			</svg>
		</div>

		<h2>
			2D Context
			<br/>
			-
			<br/>
			Simulation
		</h2>

		<p>
			You have probably seen the <code>&lt;canvas/&gt;</code> element before which is used for drawing graphics and animations.
			One way to utilize this element is through the Canvas API. This API provides an interface called <code>CanvasRenderingContext2D</code>
			which contains a bunch of methods that we can use to draw 2D objects inside the <code>&lt;canvas/&gt;</code> element.
		</p>

		<p>
			The <code>CanvasRenderingContext2D</code> is a pretty high level interface.
			It has methods for drawing objects like <code>rect(x, y, width, height)</code>,
			drawing images with <code>drawImage(image, dx, dy)</code>,
			drawing text like <code>strokeText(text, x, y [, maxWidth])</code>,
			or changing the drawing style like <code>lineWidth</code>.
			There are a lot more methods obviously, but you can already tell that these are all pretty straightforward.
		</p>

		<p>
			For the next example we will try to simulate a free falling bouncing ball.
			We will use the <code>&lt;canvas/&gt;</code> and <code>CanvasRenderingContext2D</code> to draw and animate the ball.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
const G = 9.80665;            // m/s²
const G_MS = G / 1_000_000;   // m/ms² 
const PX_M = 96 / 0.0254;     // px/m
const G_PX_MS = G_MS * PX_M;  // px/ms²

const RADIUS = 25;
const E = 0.99
const COLL_Y = canvas.height - RADIUS;

let ball = {
  pos: { x: width / 2, y: 0 },
  vel: { x: 0, y: 0 },
};
			</code>
		</pre>

		<p>
			We will start by defining our initial state and some <code>const</code>ants that we'll use in our simulated system.
			We will start with <code>G</code>ravity as defined in international units (<code>m/s²</code>) and we will convert it down to web units (<code>px/ms²</code>).
			We will specify the ball <code>RADIUS</code>.
			And we want to define a coefficient of restitution (<code>E</code>) for the bouncing ball.
			<code>COLL_Y</code> will be our collision height.
			And lastly, we will define the state of the ball with an initial <code>pos</code>ition and <code>vel</code>ocity.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
function draw() {
	ctx.clearRect(0, 0, canvas.width, canvas.height);
	ctx.beginPath();
	ctx.arc(ball.pos.x, ball.pos.y, RADIUS, 0, Math.PI * 2);
	ctx.fill();
}
			</code>
		</pre>

		<p>
			We can use our <code>CanvasRenderingContext2D</code> to draw the simulated bouncing ball.
			Every time we need to draw, we'll clear everything by drawing a <code>clearRect(x, y, width, height)</code> the size of the <code>&lt;canvas/&gt;</code>.
			We will start with <code>beginPath()</code> to create a new drawing object.
			We don't have a circle function, but we can use the <code>arc(x, y, radius, startAngle, endAngle)</code> method to draw a circle by specifying a full <code>360°</code> turn.
			And lastly we can specify that we want to <code>fill()</code> this path with color.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
function update() {
	var next = structuredClone(ball);

	var dt = Date.now() - t;
	t = Date.now();

	next.vel.y += G_PX_MS * dt;
	next.pos.y += (ball.vel.y * dt) + (G_PX_MS / 2) * (dt * dt);

	if (next.pos.y > COLL_Y) {
		let dy = COLL_Y - ball.pos.y;
		let t = (-ball.vel.y + Math.sqrt(ball.vel.y * ball.vel.y + 2 * G_PX_MS * dy)) / G_PX_MS;
		let v = G_PX_MS * t + ball.vel.y;

		next.vel.y = -v * E;
		next.pos.y = COLL_Y;
	}

	ball.vel.y = next.vel.y;
	ball.pos.y = next.pos.y;
}
			</code>
		</pre>

		<p>
			To calculate the ball's <code>next</code> <code>pos</code>ition and <code>vel</code>ocity we will use a little bit of math.
			On every frame we will calculate the change of time <code>dt</code>.
			We will need to increase our velocity by our given time delta.
			From calculus we know that acceleration is equal to the ratio of the change of velocity with respect to time, and after rearranging terms we get:
		</p>

		<p style="text-align: center">
			\(\Delta v = g\Delta t\)
		</p>

		<p>
			Similarly, we will need to increase our position by our given time delta.
			And again, from calculus we know that acceleration is equal to the second derivative of displacement(change in position). So after integrating and rearranging terms we get:
		</p>

		<p style="text-align: center">
			\(\Delta x = v_0\Delta t + \frac{1}{2}g\Delta t^2\)
		</p>

		<p>
			Now that we have our <code>next</code> state,
			we will need to check if the ball will collide with the ground.
			In the case where the ball exceeds the collision height, we will calculate the final velocity at the moment of collision.
			We will then reset the ball's <code>vel</code>ocity state to this final velocity but with opposite direction.
			And we'll also reset the ball's <code>pos</code>ition to collision height.
		</p>

		<p>
			To commit this calculated <code>next</code> state, we just assign it back to our current <code>ball</code> state.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
function frame() {
	draw();
	update();
	window.requestAnimationFrame(frame);
}
			</code>
		</pre>

		<p>
			In order to run this simulation system in a loop, we will use 
			<code>window.requestAnimationFrame()</code> which allows us to execute code at the display's frame rate.
			Our <code>frame</code> function would then start by <code>draw</code>ing the bouncing ball, it would then <code>update</code> the state of the ball,
			and will lastly pass itself as a callback to loop as soon as the browser sees fit.
		</p>

		<!-- CANVAS: 2D CONTEXT -->
		<div class="container" id="container-context-2d">
			<canvas id="canvas-context-2d" class="border"></canvas>
		</div>

		<h2>
			WebGL
			<br/>
			-
			<br/>
			3-Dimensional
		</h2>

		<p>
			Now that we've seen in our previous example how to draw in 2D, we can move on to using the <code>WebGL2RenderingContext</code> to draw 3D objects.
			This interface is an implementation of the OpenGL ES (Embedded Systems) 3.0 specification for the browser's <code>&lt;canvas/&gt;</code> element.
			This specification is a subset of the OpenGL graphics rendering API.
		</p>

		<p>
			The next example will make use of the same simulation system that we created in the last section.
			We will try to recreate the last example in 3D, but we won't have the high level API to draw objects directly,
			which means that we will have to create these ourselves.
		</p>

		<p>
			We can picture the last example in 3D by imagining a scene with a box, and a sphere bouncing inside of it.
			To gain a little perspective over our scene, we can also imagine ourselves rotating around it; in order to represent this we will use an orbiting camera.
		</p>

		<p>
			For us to draw any object we need to represent it in terms of vertices and indices.
			Let's define a vertex as a point in space where two or more lines intersect or meet, and assign an index to it for reference.
			We can use any 2 indexes to connect vertices with a line.
			And similarly, we can use 3 indexes to create a triangle/face.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
const S = 100; // Half side of the cube
function initCube() {
	const vertices = new Float32Array([
		-S, -S, -S,
		 S, -S, -S,
		 S,  S, -S,
		//...
	]);

	const indices = new Uint16Array([
		0, 1,
		1, 2, 
		//...
	]);

	var vertexBuffer = gl.createBuffer();
	var indexBuffer = gl.createBuffer();

	return function drawCube() {
		gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
		gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);
	
		gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);
		gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, indices, gl.STATIC_DRAW);
	
		// Get the attribute pointer and enable it
		var vertexPosition = gl.getAttribLocation(shaderProgram, "aVertexPosition");
		gl.enableVertexAttribArray(vertexPosition);
		gl.vertexAttribPointer(vertexPosition, 3, gl.FLOAT, false, 0, 0);
	
		gl.drawElements(gl.LINES, indices.length, gl.UNSIGNED_SHORT, 0);
	}
}
			</code>
		</pre>

		<p>
			For our box we will draw lines representing a cube.
			A cube has 8 corners or <code>vertices</code> that we will generate from its center using the half side length <code>S</code> of the cube.
			The <code>indices</code> will then represent the pair of vertices that make up our box lines.
		</p>

		<p>
			We now need a way to send this data down to our WebGL rendering pipeline in our GPU.
			We will use <code>createBuffer</code> to allocate the memory for this data.
			With <code>bindBuffer</code> we'll set the current buffer to be used.
			<code>ARRAY_BUFFER</code> just represents <code>vertex</code> data and <code>ELEMENT_ARRAY_BUFFER</code> represents <code>index</code> data.
			In this case our box data never changes so we will use <code>STATIC_DRAW</code> usage.
		</p>

		<pre>
			<code class="language-glsl hljs-grayscale">
	attribute vec4 aVertexPosition;
	uniform mat4 uModelViewMatrix;
	uniform mat4 uProjectionMatrix;
	void main(void) {
		gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
	}
			</code>
		</pre>

		<p>
			This is our vertex shader, this shader is in charge of transforming our vertex data into anything that we want.
			It is most commonly used for applying the MVP (Model-View-Projection) matrix
			to transform from local space to viewport space,
			we will look a little bit more at these matrices in a moment.
			The <code>attribute vec4 aVertexPosition</code> is the place where we will receive each vertex element.
		</p>

		<p>
			With the <code>getAttribLocation</code> method we can get back the index position of this attribute in our shader.
			Because attributes are disabled by default, we can use this index to enable the vertex attribute with <code>enableVertexAttribArray</code>.
		</p>

		<p>
			We now need to bind our vertex buffer to our vertex attribute specifying the format of our data with <code>vertexAttribPointer</code>. We pass in the index for the attribute,
			each of our vertices has <code>3</code> components: x y z, each component is of type <code>FLOAT</code>, we don't need to normalize our data,
			our data is tightly packed so our stride is <code>0</code>, and since our buffer is only used for this object vertex data, our offset is <code>0</code> as well.
		</p>

		<p>
			Lastly, we render our box by calling <code>drawElements</code>. We pass in the mode <code>LINES</code>, we set the number of indices used for rendering all the lines,
			the type of each index is <code>UNSIGNED_SHORT</code>, and no offset either.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
	function initSphere() {
		// Sphere resolution
		const SEGMENTS = 30;
		const RINGS = 30
	
		var vertexBuffer = gl.createBuffer();
		var indexBuffer = gl.createBuffer();
	
		var vertices = new Float32Array((SEGMENTS+1) * (RINGS+1) * 3);
		var indices = new Uint16Array(SEGMENTS * RINGS * 6);
	
		return function drawSphere(xx, yy, zz, r) {
			let vx = [];
			let ix = [];
	
			// Generate the vertices and indices for the sphere
			for (let i = 0; i <= RINGS; i++) {
				const phi = (i / RINGS) * Math.PI;
				const y = Math.cos(phi) * r;
	
				for (let j = 0; j <= SEGMENTS; j++) {
					const theta = (j / SEGMENTS) * 2 * Math.PI;
					const x = Math.sin(phi) * Math.cos(theta) * r;
					const z = Math.sin(phi) * Math.sin(theta) * r;
		
					vx.push(x+xx, y-yy, z+zz);
		
					if (i < RINGS && j < SEGMENTS) {
						const first = i * (SEGMENTS + 1) + j;
						const second = first + SEGMENTS + 1;
						ix.push(first, second, first + 1);
						ix.push(second, second + 1, first + 1);
					}
				}
			}
	
			vertices.set(vx);
			indices.set(ix);

			gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
			gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.DYNAMIC_DRAW);

			gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);
			gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, indices, gl.STATIC_DRAW);

			var vertexPosition = gl.getAttribLocation(shaderProgram, "aVertexPosition");
			gl.enableVertexAttribArray(vertexPosition);
			gl.vertexAttribPointer(vertexPosition, 3, gl.FLOAT, false, 0, 0);

			gl.drawElements(gl.TRIANGLES, indices.length, gl.UNSIGNED_SHORT, 0);
		}
	}
			</code>
		</pre>

		<p>
			Now that we know how to draw a box, we should be able to draw a sphere without any problem.
			The code above shows how to generate the vertices and indices for it.
			I will leave it as an exercise for you to understand how it works exactly.
		</p>

		<p>
			The differences between the sphere and the box are a few. The sphere is moving in space, so we will need to generate it every time we move it.
			There are other approaches much more efficient than this, but for our purposes this should suffice.
			Since our vertex buffer data is constantly changing we will use <code>DYNAMIC_DRAW</code> mode for better performance.
			The only other difference is that we will draw <code>TRIANGLES</code> instead of <code>LINES</code>.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
	void main(void) {
		gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0);
	}
			</code>
		</pre>

		<p>
			This is our fragment shader, this shader is in charge of determining the final color of our face.
			In this case we will just color them black <code>vec4(0.0, 0.0, 0.0, 1.0)</code>.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
function initCamera() {
	// Camera component
	const CAM = 200 * Math.sqrt(2) / 2;
	const camera = glMatrix.vec3.fromValues(CAM, CAM, CAM);

	// Set the camera perspective
	const H = canvas.width / 2;
	const V = canvas.height / 2;
	const NEAR = 1.0;
	const FAR = 1000.0;

	// Create projection and model-view matrices
	const projectionMatrix = glMatrix.mat4.create();
	const modelViewMatrix = glMatrix.mat4.create();

	glMatrix.mat4.ortho(projectionMatrix, -H, H, -V, V, NEAR, FAR);

	return function rotateSetCamera() {

		// Rotate camera
		glMatrix.vec3.rotateY(camera, camera, [0, 0, 0], Math.PI / 720);

		// Point camera to origin
		glMatrix.mat4.lookAt(modelViewMatrix, camera, [0, 0, 0], [0, 1, 0]);

		// Pass the matrices to the shaders
		var projectionMatrixUniform = gl.getUniformLocation(shaderProgram, "uProjectionMatrix");
		gl.uniformMatrix4fv(projectionMatrixUniform, false, projectionMatrix);

		var modelViewMatrixUniform = gl.getUniformLocation(shaderProgram, "uModelViewMatrix");
		gl.uniformMatrix4fv(modelViewMatrixUniform, false, modelViewMatrix);
	}
}
			</code>
		</pre>

		<p>
			The representation of a camera is given by the view and projection matrices we mentioned before.
			The math behind setting up these matrices is out of our scope, but we can use the <code>glMatrix</code> library to generate them very easily.
		</p>

		<p>
			We will define the position of our <code>camera</code> in space with a <code>vec3</code> value.
			We can use <code>mat4.ortho</code> to generate an orthographic projection matrix and
			<code>mat4.lookAt</code> to generate a view matrix from our camera position to a point in space.
			As we rotate our camera we will want to keep updating our view matrix.
		</p>

		<p>
			We can use <code>getUniformLocation</code> to get an identifier of the place in the GPU's memory where this uniform variable is located.
			Then we use this identifier to set the uniform variable in our shader to our corresponding matrix value.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
	function clear() {
		gl.clearColor(1.0, 1.0, 1.0, 1.0);
		gl.clear(gl.COLOR_BUFFER_BIT);
	}
			</code>
		</pre>

		<p>
			We can select the <code>clearColor</code> and call <code>clear</code> with the <code>COLOR_BUFFER_BIT</code> to clear the screen from any render objects.
		</p>

		<p>
			Now you can put everything in motion with a <code>frame</code> function like in the last example.
		</p>

		<!-- CANVAS: WEBGL -->
		<div class="container" id="container-webgl">
			<canvas id="canvas-webgl" class="border"></canvas>
		</div>

		<h2>
			WebGPU
			<br/>
			-
			<br/>
			Compute Shaders
		</h2>

		<p>
			WebGPU is the replacement of WebGL for the modern GPUs,
			it has more advanced features and its API is basically an abstraction layer on top of
			Vulkan, DirectX 12, Metal. It can be used with OpenGL and OpenGL ES backends as well.
		</p>

		<p>
			WebGPU can be used directly in the browser through the WebGPU API, or it can be compiled down to
			WASM by using the direct implementations: Dawn/C++ and wgpu/Rust.
		</p>

		<p>
			One of the big advantages of modern graphics APIs is the removal of shared global state.
			With WebGPU you have to define every aspect of your pipeline which results in a little more verbose but much more performant program.
		</p>

		<p>
			In the next example, we'll take advantage of compute shaders to instantiate a number of bouncing balls,
			where each ball's position and velocity is calculated independently in the GPU.
			I won't touch on the rendering pipeline since we already brushed over the core concepts in the last example with WebGL.
			Although there are big differences between the two rendering APIs, I believe that learning about compute shaders is much more fundamental.
		</p>

		<p>
			WebGPU allows you to run general-purpose parallel compute workloads using compute shaders.
			Compute shaders are similar to WebGL/OpenGL shaders, but instead of operating on graphics data to render images,
			they perform arbitrary computations for GPGPU (General-purpose computing) tasks like physics simulation, image processing, AI, etc.
		</p>

		<pre>
			<code class="language-rust hljs-grayscale">
struct Ball {
	pos: vec2&lt;f32&gt;,
	vel: vec2&lt;f32&gt;,
}

@group(0) @binding(0) var&lt;storage, read&gt; state: array&lt;Ball&gt;;
@group(0) @binding(1) var&lt;storage, read_write&gt; next: array&lt;Ball&gt;;
@group(1) @binding(0) var&lt;uniform&gt; size: vec2&lt;f32&gt;;
@group(1) @binding(1) var&lt;uniform&gt; r: f32;
@group(1) @binding(2) var&lt;uniform&gt; G: f32;
@group(1) @binding(3) var&lt;uniform&gt; dt: f32;

@compute @workgroup_size(8)
fn main(@builtin(local_invocation_index) i: u32) {
	// CALCULATE Y-AXIS VELOCITY AND POSITION
	let next_vel_y = state[i].vel.y + G * dt;
	let next_pos_y = state[i].pos.y + ((next_vel_y + state[i].vel.y) / 2.0) * dt;

	let COLL_Y = (size.y / 2.0) - r;
	if (next_pos_y &gt; COLL_Y) {
		let dy = COLL_Y - state[i].pos.y;
		let t = (-state[i].vel.y + sqrt(pow(state[i].vel.y, 2) + 2 * G * dy)) / G;
		let v = G * t + state[i].vel.y;

		next[i].vel.y = -v * 1;
		next[i].pos.y = COLL_Y;
	}
	else {
		next[i].vel.y = next_vel_y;
		next[i].pos.y = next_pos_y;
	}

	// CALCULATE X-AXIS VELOCITY AND POSITION
	let next_vel_x = state[i].vel.x;
	let next_pos_x = state[i].pos.x + state[i].vel.x * dt;

	let COLL_X = (size.x / 2.0) - r;
	if (next_pos_x &gt; COLL_X) {
		next[i].vel.x = -next_vel_x;
		next[i].pos.x = COLL_X;
	}
	else if (next_pos_x &lt; -COLL_X) {
		next[i].vel.x = -next_vel_x;
		next[i].pos.x = -COLL_X;
	}
	else {
		next[i].vel.x = next_vel_x;
		next[i].pos.x = next_pos_x;
	}
}
			</code>
		</pre>

		<p>
			The code above is a compute shader written in WGSL (WebGPU Shading Language).
			We start by defining a basic <code>struct</code> for our bouncing ball.
			It has fields for <code>pos</code>ition and <code>vel</code>ocity.
		</p>

		<p>
			We define some of our <code>binding</code> <code>var</code>iables in two <code>group</code>(s).
			The first group are 2 <code>Ball</code> <code>array</code>(s), the current <code>state</code> and the <code>next</code> state.
			We'll use <code>storage</code> buffer for this bindings since we need to write our calculated values.
		</p>

		<p>
			The second group are all of our <code>uniform</code>(s) that we'll use to calculate the next state.
			Things like the <code>size</code> of the canvas, the <code>r</code>adius of the ball, the <code>G</code>ravity and the time delta <code>dt</code>.
		</p>

		<p>
			Next we define our <code>main</code> function.
			The <code>@compute</code> decorator indicates that this function is a compute shader.
			A workgroup is a group of cells where each cell maps to an instance of a running shader program.
			The <code>@workgroup_size</code> defines how many cells are in a workgroup.
			This can be defined in 1, 2 or 3 dimensions, in this example we'll leave it as a row of 8 cells.
		</p>

		<p>
			In our function we'll use the <code>builtin</code> variable <code>local_invocation_index</code>.
			This will be the index of the local cell in our workgroup.
			We can use this to access the current and next state from our storage buffer arrays.
			From then, the code is what we've seen already to calculate the position and velocity - only this time we have a constraint for the walls as well.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
const computePipeline = device.createComputePipeline({
	layout: 'auto',
	compute: {
		module: device.createShaderModule({
			code: compWGSL
		}),
		entryPoint: 'main'
	}
});
			</code>
		</pre>

		<p>
			This is how we create a compute pipeline.
			We can specify a specific <code>layout</code> for our bindings, but in this case we'll just let the API figure it out <code>auto</code>matically.
			Our shader exists in a template literal <code>compWGSL</code> and from it we can create our shader module.
			Lastly we specify our entry function name <code>main</code>.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
// SIZE UNIFORM
const sizeUniformBuffer = device.createBuffer({
	size: Float32Array.BYTES_PER_ELEMENT * 2,
	usage: GPUBufferUsage.UNIFORM,
	mappedAtCreation: true
});
new Float32Array(sizeUniformBuffer.getMappedRange()).set([canvas.width, canvas.height]);
sizeUniformBuffer.unmap();

// RADIUS UNIFORM
const BALL_RADIUS = 25;
const radiusUniformBuffer = device.createBuffer({
	size: Float32Array.BYTES_PER_ELEMENT,
	usage: GPUBufferUsage.UNIFORM,
	mappedAtCreation: true
});
new Float32Array(radiusUniformBuffer.getMappedRange()).set([BALL_RADIUS]);
radiusUniformBuffer.unmap();

// GRAVITY UNIFORM
const G = 9.80665; // UNITS - m/s²
const G_MS = G / 1000000; // ADJUST FOR MILLISECONDS
const G_PX_MS = G_MS * 3779.5296; // ADJUST FOR PIXEL PHYSICAL SIZE
const gravityUniformBuffer = device.createBuffer({
	size: Float32Array.BYTES_PER_ELEMENT,
	usage: GPUBufferUsage.UNIFORM,
	mappedAtCreation: true
});
new Float32Array(gravityUniformBuffer.getMappedRange()).set([G_PX_MS]);
gravityUniformBuffer.unmap();

// TIME DELTA UNIFORM
const stagingElapsedUniformBuffer = device.createBuffer({
	size: Float32Array.BYTES_PER_ELEMENT,
	usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC
})
const elapsedUniformBuffer = device.createBuffer({
	size: Float32Array.BYTES_PER_ELEMENT,
	usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
});
			</code>
		</pre>

		<p>
			We mentioned before that we would need some <code>uniform</code> variables that would help us define some parameters for our system.
			For each uniform we'll <code>createBuffer</code> with the <code>size</code> of the data and the usage of the buffer <code>GPUBufferUsage.UNIFORM</code>.
			<code>mappedAtCreation</code> just means that we'll get access to the buffer memory to set an initial value.
			For the time delta we'll need a staging buffer to update the value on every frame and copy the contents to the real buffer used in our shader.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
const NO_OF_BALLS = 4;
var ballInstances = [];
for (var i = 0; i < NO_OF_BALLS; i++) {
	ballInstances.push(
		// position
		(Math.random() - 0.5) * ((canvas.width / 2) - BALL_RADIUS),
		(Math.random() - 0.5) * ((canvas.height / 2) - BALL_RADIUS),
		// velocity
		(Math.random() - 0.5) * G_PX_MS * 100,
		(Math.random() - 0.5) * G_PX_MS * 200,
	);
}

const ballInstanceBufferA = device.createBuffer({
	size: Float32Array.BYTES_PER_ELEMENT * NO_OF_BALLS * 4,
	usage: GPUBufferUsage.STORAGE | GPUBufferUsage.VERTEX,
	mappedAtCreation: true,
});

new Float32Array(ballInstanceBufferA.getMappedRange()).set(ballInstances);
ballInstanceBufferA.unmap();

const ballInstanceBufferB = device.createBuffer({
	size: Float32Array.BYTES_PER_ELEMENT * NO_OF_BALLS * 4,
	usage: GPUBufferUsage.STORAGE | GPUBufferUsage.VERTEX,
});
			</code>
		</pre>

		<p>
			Let's now create <code>4</code> balls with some random initial values for position and velocity.
			We'll add all these initial values into the <code>ballInstances</code> array.
			These are the values that we'll use inside our shader to calculate the next state.
		</p>

		<p>
			We'll use 2 buffers, 1 to keep our current state and 1 to write our next state.
			Now we <code>createBuffer</code> this time with <code>GPUBufferUsage.STORAGE</code> .
			The <code>GPUBufferUsage.VERTEX</code> indicates that the contents of this buffer will be used as vertices in our render pipeline.
		</p>

		<pre>
			<code class="language-js hljs-grayscale">
const bindGroupA = device.createBindGroup({
	layout: computePipeline.getBindGroupLayout(0),
	entries: [
		{ binding: 0, resource: { buffer: ballInstanceBufferA }},
		{ binding: 1, resource: { buffer: ballInstanceBufferB }},
	]
});

const bindGroupB = device.createBindGroup({
	layout: computePipeline.getBindGroupLayout(0),
	entries: [
		{ binding: 0, resource: { buffer: ballInstanceBufferB }},
		{ binding: 1, resource: { buffer: ballInstanceBufferA }},
	]
});

const bindGroupUniforms = device.createBindGroup({
	layout: computePipeline.getBindGroupLayout(1),
	entries: [
		{ binding: 0, resource: { buffer: sizeUniformBuffer }},
		{ binding: 1, resource: { buffer: radiusUniformBuffer }},
		{ binding: 2, resource: { buffer: gravityUniformBuffer }},
		{ binding: 3, resource: { buffer: elapsedUniformBuffer }}
	]
});
			</code>
		</pre>

		<p>
			Here we just place all of our resource buffers into bind groups that we'll send to our compute pipeline.
			The reason we need 2 bind groups for our storage buffers is we need to flip the buffers on every frame to keep updating our system with the next value.
		</p>

		<pre>
			<code>
let t = Date.now(), ff = 1;

async function frame() {
	// TIME DELTA UNIFORM
	await stagingElapsedUniformBuffer.mapAsync(GPUMapMode.WRITE);
	new Float32Array(stagingElapsedUniformBuffer.getMappedRange()).set([Date.now() - t]);
	stagingElapsedUniformBuffer.unmap();

	t = Date.now();

	// COMMAND ENCODER
	const commandEncoder = device.createCommandEncoder();

	// COPY ELAPSED TIME TO UNIFORM
	commandEncoder.copyBufferToBuffer(
		stagingElapsedUniformBuffer, 0,
		elapsedUniformBuffer, 0, 
		Float32Array.BYTES_PER_ELEMENT);

	// COMPUTE
	const passEncoderCompute = commandEncoder.beginComputePass();
	passEncoderCompute.setPipeline(computePipeline);
	passEncoderCompute.setBindGroup(0, ff ? bindGroupA : bindGroupB);
	passEncoderCompute.setBindGroup(1, bindGroupUniforms);
	passEncoderCompute.dispatchWorkgroups(1);
	passEncoderCompute.end();

	// RENDERING...

	// SUBMIT COMMANDS
	device.queue.submit([commandEncoder.finish()]);

	ff = 1 - ff;
	window.requestAnimationFrame(frame);
}
			</code>
		</pre>

		<p>
			To finish, we put everything into motion in our <code>frame</code> function.
			We update our staging time delta uniform buffer.
			We <code>createCommandEncoder</code> and we use it to write a command for copying our staging buffer into our real delta time buffer.
			We start a new pass and we use this encoder to set our pipeline, set the bind groups, dispatch 1 workgroup and end the pass.
			We can later submit this encoded data into our queue to be processed by our GPU.
			As we mentioned before, we need to switch our storage buffers and that is what we use the <code>ff</code> variable for.
		</p>

		<!-- CANVAS: WEBGPU -->
		<div class="container" id="container-webgpu">
			<canvas id="canvas-webgpu" class="border"></canvas>
			<p id="non-supported-webgpu" class="border hidden center"><code>WebGPU is not available in your browser.</code></p>
		</div>

		<h2>
			Conclusion
		</h2>

		<p>
			I hope that the examples provided you with a little more knowledge of
			the core concepts presented and that it has inspired you
			to make a little more research into any of these topics.
		</p>

		<br>

		<script src="vendor/gl-matrix-min.js"></script>
		<script src="context2d.js"></script>
		<script src="webgl.js"></script>
		<script src="webgpu.js"></script>
	</div>
</body>
</html>